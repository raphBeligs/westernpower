{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adaptive-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, BayesianRidge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from pvlib import location\n",
    "from pvlib import irradiance\n",
    "from pvlib import clearsky, atmosphere, solarposition\n",
    "import predictions_algorithmes as pa\n",
    "\n",
    "class DataPreprocesser:\n",
    "    weather_path=None\n",
    "    demand_path=None\n",
    "    solar_path=None\n",
    "    df=None\n",
    "    def __init__(self, weather_path, demand_path, solar_path):\n",
    "        self.weather_path = weather_path\n",
    "        self.demand_path = demand_path\n",
    "        self.solar_path = solar_path\n",
    "    def load_df(self):\n",
    "        weather_df = pd.read_csv(self.weather_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        solar_df = pd.read_csv(self.solar_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        demand_df = pd.read_csv(self.demand_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        df=pd.merge(demand_df,solar_df , how='outer', left_index=True, right_index=True)\n",
    "        df=pd.merge(df,weather_df, how='outer', left_index=True, right_index=True)\n",
    "        df['week']=pd.Int64Index(df.index.isocalendar().week)\n",
    "        df['dow']=df.index.dayofweek\n",
    "        df['date'] = df.index.date\n",
    "        df['hour'] = df.index.hour\n",
    "        df['sp'] = df.hour*2 +df.index.minute/30 + 1\n",
    "        self.df = df\n",
    "    def set_df(self,df):\n",
    "        self.df = df\n",
    "    def remove_nan(self):\n",
    "        self.df = self.df.dropna(subset = ['demand_MW']).interpolate()\n",
    "    def interpolate_df(self):\n",
    "        self.df = self.df.interpolate()\n",
    "    def get_zenith_angle(self, df=None):\n",
    "        lat = -4.034\n",
    "        long = 50.33\n",
    "        if df is None:\n",
    "            self.df['zenith_angle'] = solarposition.get_solarposition(self.df.index, lat, long)['apparent_zenith'].values\n",
    "            return self.df\n",
    "        else:\n",
    "            df['zenith_angle'] = solarposition.get_solarposition(df.index, lat, long)['apparent_zenith'].values\n",
    "            return df\n",
    "    def get_poa_and_ghi_irradiance(self, df=None):\n",
    "    \n",
    "        # For this example, we will be using Golden, Colorado\n",
    "        tz = 'UTC'\n",
    "        lat = 50.33\n",
    "        lon = -4.034\n",
    "        # lat, lon = 39.755, -105.221\n",
    "\n",
    "        # Create location object to store lat, lon, timezone\n",
    "        site = location.Location(lat, lon, tz=tz)\n",
    "\n",
    "\n",
    "        # Calculate clear-sky GHI and transpose to plane of array\n",
    "        # Define a function so that we can re-use the sequence of operations with\n",
    "        # different locations\n",
    "        def get_irradiance(site_location, date, tilt, surface_azimuth, periods):\n",
    "            # Creates one day's worth of 10 min intervals\n",
    "            times = pd.date_range(date, freq='30min', periods=periods,\n",
    "                                  tz=site_location.tz)\n",
    "            # Generate clearsky data using the Ineichen model, which is the default\n",
    "            # The get_clearsky method returns a dataframe with values for GHI, DNI,\n",
    "            # and DHI\n",
    "        #     print(times)\n",
    "            clearsky = site_location.get_clearsky(times,model='ineichen')\n",
    "            # Get solar azimuth and zenith to pass to the transposition function\n",
    "            solar_position = site_location.get_solarposition(times=times)\n",
    "            # Use the get_total_irradiance function to transpose the GHI to POA\n",
    "            POA_irradiance = irradiance.get_total_irradiance(\n",
    "                surface_tilt=tilt,\n",
    "                surface_azimuth=surface_azimuth,\n",
    "                dni=clearsky['dni'],\n",
    "                ghi=clearsky['ghi'],\n",
    "                dhi=clearsky['dhi'],\n",
    "                solar_zenith=solar_position['apparent_zenith'],\n",
    "                solar_azimuth=solar_position['azimuth'])\n",
    "\n",
    "            # Return DataFrame with only GHI and POA\n",
    "            return pd.DataFrame({'GHI': clearsky['ghi'],\n",
    "                                 'POA': POA_irradiance['poa_global']})\n",
    "        if df is None:\n",
    "            \n",
    "            df_solar_irr = get_irradiance(site, '{}-{}-{}'.format(self.df.index.date[0].year, self.df.index.date[0].month, \n",
    "                                                                  self.df.index.date[0].day), 90, 180, len(self.df))\n",
    "    #         new_df = df.copy()\n",
    "            self.df['GHI'] = df_solar_irr['GHI'].values\n",
    "            self.df['POA'] = df_solar_irr['POA'].values\n",
    "\n",
    "            return self.df\n",
    "        else:\n",
    "            df_solar_irr = get_irradiance(site, '{}-{}-{}'.format(df.index.date[0].year, df.index.date[0].month, \n",
    "                                                                  df.index.date[0].day), 90, 180, len(df))\n",
    "    #         new_df = df.copy()\n",
    "            df['GHI'] = df_solar_irr['GHI'].values\n",
    "            df['POA'] = df_solar_irr['POA'].values\n",
    "            return df\n",
    "\n",
    "    def build_input_for_ml_algo(self, X_column_names, y_column_names):\n",
    "        if self.df is None:\n",
    "            print('df is None, you have to load it')\n",
    "            return self.df\n",
    "        X = self.df[X_column_names].to_numpy()\n",
    "        y = self.df[y_column_names].to_numpy()[:,0]\n",
    "        return X, y\n",
    "    def get_columns_of_group_names(self,group_names, location_numbers, df=None):\n",
    "        columns_names = []\n",
    "        for name in group_names:\n",
    "            for i in location_numbers:\n",
    "                column_name = '{}_location{}'.format(name, i)\n",
    "                if df is None:\n",
    "                    this_df = self.df\n",
    "                else:\n",
    "                    this_df = df\n",
    "                if column_name in this_df.columns.to_list():\n",
    "                    columns_names.append(column_name)\n",
    "                else:\n",
    "                    print('{} is not in df columns'.format(column_name))\n",
    "        return columns_names\n",
    "    \n",
    "\n",
    "class BatteryPowerDispatcher:\n",
    "    def __init__(self):\n",
    "        return \n",
    "    def format_dispatch_columns(date):\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        day = date.day\n",
    "        return \"{}{}{}\".format(str(year).zfill(4), str(month).zfill(2),str(day).zfill(2))\n",
    "    def get_ideal_discharge_dispatch(df,date, battery_charge=6):#afternoon discharge\n",
    "    \n",
    "        sl  = df.loc[(df.index.date == date)&(df['sp']>=32)&(df['sp']<=42),['demand_MW','pv_power_mw','hour']]\n",
    "        peak_ini = sl['demand_MW'].max()\n",
    "\n",
    "        peak_target  = peak_ini-2.5\n",
    "        discharge = (sl['demand_MW']-peak_target).clip(lower = 0)\n",
    "\n",
    "        energy =discharge.sum()*0.5\n",
    "        sp = len(discharge[discharge>0])\n",
    "    \n",
    "        while (energy>battery_charge):\n",
    "\n",
    "            peak_target  =  peak_target +0.01\n",
    "            discharge = (sl['demand_MW']-peak_target).clip(lower=0)\n",
    "            energy =discharge.sum()*0.5\n",
    "        \n",
    "        return(discharge,peak_ini,peak_target)\n",
    "    \n",
    "    def get_ideal_discharge_dispatch_in_a_week(self,df, start_date, max_battery_charge_in_week=[6,6,6,6,6,6,6]):\n",
    "        res = pd.DataFrame(columns = ['peak_ini','peak_target','energy','duration','week','dow'])\n",
    "        dispatch_summary = pd.DataFrame(index= range(32,43))\n",
    "        idx = 0\n",
    "        for i in range(0,7):\n",
    "            date = start_date + datetime.timedelta(days=i)\n",
    "            week = date.isocalendar()[1]\n",
    "            dow = date.weekday()\n",
    "            discharge,peak_ini,peak_target = self.get_ideal_discharge_dispatch(df,date, max_battery_charge_in_week[i])\n",
    "            energy = discharge.sum()*0.5\n",
    "            duration = len(discharge[discharge>0])\n",
    "            dispatch_summary[self.format_dispatch_columns(date)]=discharge.values\n",
    "            idx = idx+1\n",
    "            res.loc[idx,:] = [peak_ini,peak_target,energy,duration,week,dow]\n",
    "        return (dispatch_summary, res)\n",
    "    \n",
    "    def get_charge_of_battery_repartition(df, date, max_charge=6):\n",
    "        solar_power  = df.loc[(df.index.date == date)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        max_power = 2.5\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_mw'].apply(lambda x: min(x, max_power))\n",
    "        max_charge_from_solar = solar_power['pv_power_norm'].sum()*0.5\n",
    "        charge_from_solar = min(max_charge_from_solar, max_charge)\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_norm']*charge_from_solar / max_charge_from_solar\n",
    "        max_charge_from_grid = max_charge-charge_from_solar\n",
    "        battery_B = pd.DataFrame(data=solar_power['pv_power_norm'].to_list(),columns=['solar_B'],index=solar_power.index)\n",
    "        charge_power_from_grid = pd.DataFrame(columns=['grid_B'])\n",
    "        charge_from_grid = 0\n",
    "        solar_power_ordered = solar_power.copy()\n",
    "        solar_power_ordered['ind'] = solar_power_ordered['sp'].values\n",
    "        solar_power_ordered = solar_power_ordered.sort_values('pv_power_mw', ascending=False)\n",
    "        for i in range(len(solar_power_ordered)):\n",
    "            idx = solar_power_ordered['ind'].values[i]\n",
    "            power_from_solar = solar_power_ordered['pv_power_norm'].values[i]\n",
    "            charge_power_from_grid.loc[idx,:] = min(max(max_power - power_from_solar,0), max(max_charge_from_grid - charge_from_grid,0)*2)\n",
    "            charge_from_grid = charge_power_from_grid['grid_B'].sum()*0.5\n",
    "        charge_power_from_grid.sort_index()\n",
    "        battery_B['sp'] = solar_power['sp'].to_list()\n",
    "        battery_B['grid_B'] = charge_power_from_grid['grid_B'].to_list()\n",
    "        battery_B['B'] = battery_B['solar_B'] + battery_B['grid_B']\n",
    "        return (charge_from_solar, charge_from_grid, battery_B)\n",
    "    \n",
    "    def get_charge_of_battery_repartition3(df, date, max_charge=6):\n",
    "        solar_power  = df.loc[(df.index.date == date)&(df['sp']<=31),['pv_power_mw','sp', 'GHI', 'POA']]\n",
    "        max_power = 2.5\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_mw'].apply(lambda x: min(max(x,0), max_power))\n",
    "        max_charge_from_solar = solar_power['pv_power_norm'].sum()*0.5\n",
    "        charge_from_solar = min(max_charge_from_solar, max_charge)\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_norm']*charge_from_solar / max_charge_from_solar\n",
    "        max_charge_from_grid = max_charge-charge_from_solar\n",
    "        max_GHI = solar_power['GHI'].max()\n",
    "        solar_power['diff_GHI'] = (solar_power['GHI']*2.5/max_GHI-solar_power['pv_power_norm']).apply(lambda x: max(x,0))\n",
    "        max_diff = solar_power['diff_GHI'].sum()*0.5\n",
    "\n",
    "        battery_B = pd.DataFrame(data=solar_power['pv_power_norm'].to_list(),columns=['solar_B'],index=solar_power.index)\n",
    "        battery_B['grid_B'] = solar_power['diff_GHI'].values*max_charge_from_grid/max_diff\n",
    "\n",
    "        battery_B['sp'] = solar_power['sp'].to_list()\n",
    "        battery_B['B'] = battery_B['solar_B'] + battery_B['grid_B']\n",
    "        return (charge_from_solar, max_charge_from_grid, battery_B)\n",
    "    \n",
    "    def get_charge_of_battery_repartition2(df, date, max_charge=6):\n",
    "        solar_power = df.loc[(df.index.date == date)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        solar_power['ind'] = solar_power['sp'].apply(lambda x: int(x))\n",
    "        max_power = 2.5\n",
    "        uncertainty = 0.8\n",
    "        ratio = solar_power['pv_power_mw'].apply(lambda x: min(x,max_power)).sum()*0.5\n",
    "        if ratio > 1.5:\n",
    "            coeff = uncertainty\n",
    "        elif ratio > 1.2:\n",
    "            coeff = 0.9\n",
    "        else:\n",
    "            coeff = 1\n",
    "        solar_power = solar_power.sort_values('pv_power_mw', ascending=False)\n",
    "        max_solar_charge = min(max_charge,solar_power['pv_power_mw'].apply(lambda x: min(x,2,5)).sum()*0.5)\n",
    "        max_grid_charge = max_charge - max_solar_charge\n",
    "        solar_charge = 0\n",
    "        grid_charge = 0\n",
    "        battery_B = pd.DataFrame(columns = ['ind', 'sp', 'solar_B', 'grid_B'])\n",
    "        for i in range (len(solar_power)):\n",
    "            solar_B = min(coeff*min(solar_power['pv_power_mw'][i], max_power), max(0,max_solar_charge - solar_charge)*2)\n",
    "            grid_B = min(max_power-solar_B, max(0,(max_grid_charge-grid_charge)*2))\n",
    "            battery_B.loc[i, :] = [solar_power['ind'][i], solar_power['sp'][i], solar_B, grid_B]\n",
    "            solar_charge += solar_B*0.5\n",
    "            grid_charge += grid_B*0.5\n",
    "        battery_B['B'] = battery_B['solar_B'] + battery_B['grid_B']\n",
    "        battery_B =battery_B.sort_values('ind', ascending = True)\n",
    "        battery_B.index = df.loc[(df.index.date == date)&(df['sp']<=31),:].index\n",
    "        battery_B = battery_B.drop('ind', axis=1)\n",
    "        return (solar_charge, grid_charge, battery_B)\n",
    "    \n",
    "    def get_solar_energy_proportion_by_day_in_a_week(self,df,start_date, charge_method=3,max_battery_charge_in_week=[6,6,6,6,6,6,6]):\n",
    "        B = pd.DataFrame(index= range(1,32))\n",
    "        p_solar = []\n",
    "        for i in range(7):\n",
    "            date = start_date + datetime.timedelta(days=i)\n",
    "            if charge_method == 1:\n",
    "                charge_from_solar, charge_from_grid, battery_B = self.get_charge_of_battery_repartition(\n",
    "                    df, date, max_battery_charge_in_week[i])\n",
    "            elif charge_method == 2:\n",
    "                charge_from_solar, charge_from_grid, battery_B = self.get_charge_of_battery_repartition2(\n",
    "                    df,date, max_battery_charge_in_week[i])\n",
    "            elif charge_method == 3:\n",
    "                charge_from_solar, charge_from_grid, battery_B = self.get_charge_of_battery_repartition3(\n",
    "                    df,date, max_battery_charge_in_week[i])\n",
    "            else:\n",
    "                print(\"ERROR : charge method in (1,2)\")\n",
    "                return None, None\n",
    "            B[self.format_dispatch_columns(date)] = battery_B['B'].to_list()\n",
    "            p_solar.append(charge_from_solar/6)\n",
    "        return p_solar, B\n",
    "    def get_max_solar_energy_available(df, date):\n",
    "        solar_power  = df.loc[(df.index.date == date)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        return min(6,solar_power['pv_power_mw'].apply(lambda x: min(2.5, x)).sum()*0.5)\n",
    "    def get_max_solar_energy_available_in_a_week(self,df, start_date):\n",
    "        max_solar_energy_available = []\n",
    "        for i in range(7):\n",
    "            date = start_date + datetime.timedelta(days=i)\n",
    "            max_solar_energy_available.append(self.get_max_solar_energy_available(df, date))\n",
    "        return max_solar_energy_available\n",
    "    def get_end_of_the_day_dispatch(self,start_date):\n",
    "        B_end_of_the_day = pd.DataFrame(index= range(43,49))\n",
    "        for i in range(0,7):\n",
    "            date = start_date + datetime.timedelta(days=i)\n",
    "            B_end_of_the_day[self.format_dispatch_columns(date)]=0\n",
    "        return B_end_of_the_day\n",
    "    def get_all_dispatch_in_a_week(self,df, start_date, charge_method=3,full_solar=False):\n",
    "        if full_solar:\n",
    "            max_battery_charge_in_week = self.get_max_solar_energy_available_in_a_week(self, df, start_date)\n",
    "        else:\n",
    "            max_battery_charge_in_week = [6,6,6,6,6,6,6]\n",
    "        p_solar, B_charge = self.get_solar_energy_proportion_by_day_in_a_week(self,df, start_date, charge_method,max_battery_charge_in_week)\n",
    "        B_discharge, res = self.get_ideal_discharge_dispatch_in_a_week(self, df, start_date, max_battery_charge_in_week)\n",
    "        max_battery_charge_in_week = (B_discharge.sum()/2).values.tolist()\n",
    "        p_solar, B_charge = self.get_solar_energy_proportion_by_day_in_a_week(self,df, start_date, charge_method,max_battery_charge_in_week)\n",
    "        B_discharge = -B_discharge\n",
    "        B_end_of_the_day = self.get_end_of_the_day_dispatch(self,start_date)\n",
    "        B_total = B_charge.append(B_discharge)\n",
    "        B_total = B_total.append(B_end_of_the_day)\n",
    "        return B_total\n",
    "    def format_dispatching_for_competition(B, index):\n",
    "        final_B = []\n",
    "        for column in B.columns.to_list():\n",
    "            final_B.append(B[column])\n",
    "        final_B = pd.concat(final_B, ignore_index=True)\n",
    "        final_B.index = index\n",
    "        final_B = pd.DataFrame(final_B, columns=['charge_MW'])\n",
    "        return final_B\n",
    "    \n",
    "class MachineLearningResearcher:\n",
    "    param_grids = {}\n",
    "    models = {}\n",
    "    X = None\n",
    "    y = None\n",
    "    scores = {}\n",
    "    best_score = {}\n",
    "    def __init__(self, X, y):\n",
    "        self.param_grids['SVR'] = {'kernel': ['rbf'], 'C': [0.2, 0.4, 0.6, 0.8, 1.0], 'gamma': ['scale', 'auto'], 'epsilon': [0.1,0.05,0.2]}\n",
    "        self.param_grids['KNeighborsRegressor'] = {'n_neighbors': np.arange(3,100).tolist()}\n",
    "        self.param_grids['GradientBoostingRegressor'] = {'loss': ['ls'], 'n_estimators': [50,100, 150, 200], 'learning_rate': [0.025,0.03,0.04,0.05,0.075,0.1,0.15,0.2,0.5]}\n",
    "        self.param_grids['Lasso, Ridge, ElasticNet'] = {'alpha': np.round(np.arange(0.1,1.1, 0.1), decimals=1).tolist()}\n",
    "        self.param_grids['RandomForestRegressor'] = {'n_estimators': np.arange(50, 500, 50).tolist()}\n",
    "        self.models['SVR'] = [SVR()]\n",
    "        self.models['KNeighborsRegressor'] = [KNeighborsRegressor()]\n",
    "        self.models['GradientBoostingRegressor'] = [GradientBoostingRegressor()]\n",
    "        self.models['Lasso, Ridge, ElasticNet'] = [Lasso(), Ridge(), ElasticNet()]\n",
    "        self.models['RandomForestRegressor'] = [RandomForestRegressor()]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def compute_best_scores_and_params_of_ml_algos(self,X, y, models, param_grid):\n",
    "        search_results = {}\n",
    "        search_results['best_model'] = None\n",
    "        search_results['best_scores'] = 0\n",
    "        search_results['best_parameters'] = None\n",
    "        for model in models:\n",
    "            search = GridSearchCV(model, param_grid, cv=5)\n",
    "            search.fit(X, y)\n",
    "            if (search.best_score_ > search_results['best_scores']):\n",
    "                search_results['best_model'] = model\n",
    "                search_results['best_scores'] = search.best_score_\n",
    "                search_results['best_parameters'] = search.best_params_\n",
    "        return search_results\n",
    "    def display_ml_algo_scores(self, scores=None):\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        if scores is None:\n",
    "            algo_scores = self.scores\n",
    "        else:\n",
    "            algo_scores = scores\n",
    "        for model_name in algo_scores:\n",
    "            ax.scatter([model_name], [algo_scores[model_name]['best_scores']], label=model_name)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "        return\n",
    "    def get_best_scores_and_params_of_ml_algos(self, models_names, param_grid=None):\n",
    "        if param_grid is None:\n",
    "            self.scores[models_names] = self.compute_best_scores_and_params_of_ml_algos(self.X, self.y, self.models[models_names], self.param_grids[models_names])\n",
    "        else:\n",
    "            self.scores[models_names] = self.compute_best_scores_and_params_of_ml_algos(self.X, self.y, self.models[models_names], param_grid) \n",
    "        return self.scores[models_names]\n",
    "    def get_best_model_with_best_score(self, scores=None):\n",
    "        def get_best_score(scores):\n",
    "            best_score = {}\n",
    "            best_score['best_scores'] = 0\n",
    "            for score_name in scores:\n",
    "                if float(scores[score_name]['best_scores']) > float(best_score['best_scores']):\n",
    "                    best_score = scores[score_name]\n",
    "            return best_score\n",
    "        if scores is None:\n",
    "            self.best_score = get_best_score(self.scores)\n",
    "        else:\n",
    "            self.best_score = get_best_score(scores)\n",
    "        return self.best_score\n",
    "    \n",
    "class DataVisualiser:\n",
    "    def __init__():\n",
    "        return\n",
    "    def display_correlation_color_map(df, columns_names):\n",
    "        f, ax = plt.subplots(figsize=(20,20))\n",
    "        sns.heatmap(df[columns_names].corr(), annot=True, square=True, cmap = 'coolwarm')\n",
    "        plt.show()\n",
    "    def pair_plot(df, columns_names, hue_name):\n",
    "        if len(columns_names) != 3:\n",
    "            print('columns_names should have exactly 3 names, that\\'s not the case here : ', columns_names)\n",
    "        elif not(isinstance(hue_name, str)):\n",
    "            print('hue_name should be a string, that\\'s not the case here : ', hue_name)\n",
    "        else:\n",
    "            sns.pairplot(data=df[columns_names], hue=hue_name)\n",
    "\n",
    "\n",
    "class MLPredictor:\n",
    "    def __init__(self, data_preprocess, start_date_pred):\n",
    "        self.data_preprocess = data_preprocess\n",
    "        self.start_date_pred = start_date_pred\n",
    "        self.predicted_df = data_preprocess.df.loc[(data_preprocess.df.index.date >= start_date_pred+datetime.timedelta(days=-7)) &\n",
    "                                                   (data_preprocess.df.index.date < start_date_pred), \n",
    "                                                   ['week', 'dow', 'sp', 'hour', 'zenith_angle']]\n",
    "        self.predicted_df.index = self.predicted_df.index + pd.DateOffset(7)\n",
    "        self.predicted_df['week']=pd.Int64Index(self.predicted_df.index.isocalendar().week)\n",
    "        self.predicted_df['dow']=self.predicted_df.index.dayofweek\n",
    "        self.predicted_df['hour'] = self.predicted_df.index.hour\n",
    "        self.predicted_df['sp'] = self.predicted_df.hour*2 +self.predicted_df.index.minute/30 + 1\n",
    "        DataPreprocesser.get_zenith_angle(DataPreprocesser, self.predicted_df)\n",
    "        DataPreprocesser.get_poa_and_ghi_irradiance(DataPreprocesser, self.predicted_df)\n",
    "        \n",
    "    def get_field_previous_week(self, field_name):\n",
    "        field_prediction = self.data_preprocess.df.loc[(self.data_preprocess.df.index.date >= self.start_date_pred+datetime.timedelta(days=-7)) &\n",
    "                                                   (self.data_preprocess.df.index.date < self.start_date_pred), field_name].values\n",
    "        if self.predicted_df is not None:\n",
    "            self.predicted_df[field_name] = field_prediction \n",
    "            return self.predicted_df\n",
    "        return field_prediction\n",
    "    def get_demand_previous_week(self):\n",
    "        return self.get_field_previous_week('demand_MW')\n",
    "    def get_solar_power_previous_week(self):\n",
    "        return self.get_field_previous_week('pv_power_mw')\n",
    "    def get_weather_prediction(self,weather_path, pred_df=None):\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = demand_pred\n",
    "        weather_prediction = pd.read_csv(weather_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        predicted_df = pd.merge(predicted_df,weather_prediction, how='outer', left_index=True, right_index=True)\n",
    "        predicted_df = predicted_df.dropna(subset = ['demand_MW']).interpolate()\n",
    "        self.predicted_df = predicted_df\n",
    "        return self.predicted_df\n",
    "    def predict_demand_from_past_and_weather(self, model, nb_week_before=4, start_date_prediction=None, data=None, \n",
    "                                             pred_df=None, weather_cols=None):\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if weather_cols is None:\n",
    "            weather_columns = self.data_preprocess.get_columns_of_group_names(['temp'], [1,2,5,6])\n",
    "            weather_columns.append('dow')\n",
    "            weather_columns.append('sp')\n",
    "        else:\n",
    "            weather_columns = weather_cols\n",
    "        if start_date_prediction is None:\n",
    "            start_date_pred = self.start_date_pred\n",
    "        else:\n",
    "            start_date_pred = start_date_prediction\n",
    "        data_train = data_train[(data_train.index.date >= (start_date_pred+datetime.timedelta(days=-nb_week_before*7))) & \n",
    "                                (data_train.index.date < start_date_pred)]\n",
    "        X = data_train[weather_columns].to_numpy()\n",
    "        y = data_train['demand_MW'].to_numpy()\n",
    "        model.fit(X,y)\n",
    "        predicted_df['demand_MW'] = model.predict(predicted_df[weather_columns].values)\n",
    "        self.predicted_df = predicted_df\n",
    "        return predicted_df\n",
    "        \n",
    "    def pred_demand_with_forecast_method_and_average_with_previous_weeks(self,df, forecast_dir, first_day_pred, field, \n",
    "                                                                         predicted_df=None,compute_forecast=False,\n",
    "                                                                        forecast_model=RandomForestRegressor(random_state=2019, n_estimators=450),\n",
    "                                                                        nb_weeks_for_train=5, lags_list=[1,2,3,4,42,47,48,48*7],\n",
    "                                                                        columns_pred = None):\n",
    "        if predicted_df is None:\n",
    "            pred_df = self.predicted_df\n",
    "        else:\n",
    "            pred_df = predicted_df\n",
    "        if columns_pred is None:\n",
    "            cols_pred = DataPreprocesser.get_columns_of_group_names(DataPreprocesser,['temp'], [1,2,5,6], df=df)\n",
    "            cols_pred += DataPreprocesser.get_columns_of_group_names(DataPreprocesser,['solar'], [1,4],df=df)\n",
    "            cols_pred.append('sp')\n",
    "            cols_pred.append('dow')\n",
    "        else:\n",
    "            cols_pred = columns_pred\n",
    "        endog_exog_df = pred_df[cols_pred].copy()\n",
    "        endog_exog_df = pd.concat([df[cols_pred], endog_exog_df])\n",
    "        f = pa.Forecaster()\n",
    "        if compute_forecast:\n",
    "            f.recursive_rectify_weeks_before(df, field,first_day_pred, endog_exog_df, lags_list, forecast_dir, \n",
    "                                     forecast_model,nb_days_for_train=nb_weeks_for_train*7)\n",
    "        rec_preds = pa.Forecaster.apply_ml_on_predictions_weeks_before(df, os.path.join(forecast_dir, field), first_day_pred, endog_exog_df, field)\n",
    "        lags_demand_3_weeks_before = pa.DataPreprocesser.get_lags_and_median_and_mean_predict_and_train_df(df, field,first_day_pred)\n",
    "        \n",
    "        pred_df[field] = (rec_preds + lags_demand_3_weeks_before.loc[(lags_demand_3_weeks_before.index.date >= first_day_pred)\n",
    "                                                                                             & (lags_demand_3_weeks_before.index.date < first_day_pred + \n",
    "                                                                                            datetime.timedelta(days=7)), 'median_{}'.format(field)].values)/2\n",
    "        return pred_df\n",
    "    def predict_pv_power_smooth_and_square_irr(self, predicted_df=None, df=None, first_day_pred=None, nb_weeks_for_train_model=5):\n",
    "        if predicted_df is None:\n",
    "            pred_df = self.predicted_df\n",
    "        else:\n",
    "            pred_df = predicted_df\n",
    "        if df is None:\n",
    "            this_df = self.data_preprocess.df\n",
    "        else:\n",
    "            this_df = df\n",
    "        if first_day_pred is None:\n",
    "            start_date_pred = self.start_date_pred\n",
    "        else:\n",
    "            start_date_pred = first_day_pred\n",
    "        mlp = pa.MLPredictor\n",
    "        pv_power_pred_rectify, pv_power_pred = mlp.predict_pv_power(this_df, pred_df, start_date_pred, nb_days_for_train_model=7*nb_weeks_for_train_model)\n",
    "        pred_df['pv_power_mw'] = pv_power_pred_rectify\n",
    "        if predicted_df is None:\n",
    "#             self.predicted_df['pv_power_mw'] = pv_power_pred_rectify\n",
    "            return\n",
    "        return this_df, pv_power_pred_rectify, pv_power_pred\n",
    "    def predict_solar_power_from_weather(self, model, data=None, pred_df=None, weather_cols=None):\n",
    "        def solar_power_prediction_function(x, model, x_solar):\n",
    "            if x_solar == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return model.predict(x)[0]\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if weather_cols is None:\n",
    "            weather_columns = self.data_preprocess.get_columns_of_group_names(['solar'], [1,2,3,5,6])\n",
    "            weather_columns += self.data_preprocess.get_columns_of_group_names(['temp'], [1,2])\n",
    "            weather_columns.append('sp')\n",
    "        else:\n",
    "            weather_columns = weather_cols\n",
    "        X = data_train.loc[data_train['solar_location1'] > 0, weather_columns].values\n",
    "        y = data_train.loc[data_train['solar_location1'] > 0, 'pv_power_mw'].values\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        predicted_df['pv_power_mw'] = predicted_df.apply(lambda x: solar_power_prediction_function(\n",
    "            np.array([x[weather_columns].to_numpy()]), model, x['solar_location1']), axis=1)\n",
    "        self.predicted_df = predicted_df\n",
    "        return predicted_df\n",
    "    def predict_solar_power_weeks_before(self, model, nb_week_before=5, start_date_prediction=None, \n",
    "                                         data=None, pred_df=None, weather_cols=None):\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if start_date_prediction is None:\n",
    "            start_date_pred = self.start_date_pred\n",
    "        else:\n",
    "            start_date_pred = start_date_prediction\n",
    "        data_train = data_train[(data_train.index.date >= (start_date_pred+datetime.timedelta(days=-nb_week_before*7))) & \n",
    "                                (data_train.index.date < start_date_pred)]\n",
    "        return self.predict_solar_power_from_weather(model, data=data_train, weather_cols=weather_cols)\n",
    "class ScoreComputer:\n",
    "    def __init__(self, B_path):\n",
    "        B = pd.read_csv(B_path, parse_dates=['datetime'],index_col=['datetime'])\n",
    "        B['week']=pd.Int64Index(B.index.isocalendar().week)\n",
    "        B['dow']=B.index.dayofweek\n",
    "        B['hour'] = B.index.hour\n",
    "        B['sp'] = B.hour*2 + B.index.minute/30 + 1\n",
    "        self.B = B\n",
    "        \n",
    "    def compute_r_peak(self,demand_and_solar_power,date, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        demand_discharge = demand_and_solar_power.loc[(demand_and_solar_power.index.date == date)\n",
    "                                                      &(demand_and_solar_power['sp']>=32)&\n",
    "                                          (demand_and_solar_power['sp']<=42),'demand_MW']\n",
    "        B_discharge = B.loc[(B.index.date == date) &(B['sp']>=32) & (B['sp']<=42),'charge_MW']\n",
    "        old_peak = demand_discharge.max()\n",
    "        if old_peak == 0:\n",
    "            return 0\n",
    "        new_peak = (B_discharge + demand_discharge).max()\n",
    "        return 100*(old_peak-new_peak)/old_peak\n",
    "    def compute_p_solar(self,demand_and_solar_power, date, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        solar_power_for_charge = demand_and_solar_power.loc[(demand_and_solar_power.index.date == date) &\n",
    "                                                            (demand_and_solar_power['sp']<=31),['pv_power_mw']]\n",
    "        B_charge = B.loc[(B.index.date == date) & (B['sp']<=31),['charge_MW']]\n",
    "        solar_power_for_charge = solar_power_for_charge.merge(B_charge, how='outer', left_index=True, right_index=True)\n",
    "        battery_charge = B_charge['charge_MW'].sum()*0.5\n",
    "        solar_power_for_charge['charge_from_solar_MW'] = solar_power_for_charge.apply(lambda x: min(x['pv_power_mw'], x['charge_MW']), axis=1)\n",
    "        battery_charge_from_solar = solar_power_for_charge['charge_from_solar_MW'].sum()*0.5\n",
    "        if battery_charge == 0:\n",
    "            p_solar = 0\n",
    "        else:\n",
    "            p_solar = battery_charge_from_solar / battery_charge\n",
    "        p_grid = 1-p_solar\n",
    "        return p_solar, p_grid, battery_charge, solar_power_for_charge\n",
    "    def compute_scores(self, demand_and_solar_power, start_date, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        scores = pd.DataFrame(columns = ['r_peak', 'p_solar', 's'])\n",
    "        idx = 0\n",
    "        with tqdm(total=7, file=sys.stdout) as pbar:\n",
    "            for i in range(7):\n",
    "                date = start_date + datetime.timedelta(days=i)\n",
    "                r_peak = self.compute_r_peak(demand_and_solar_power, date, B)\n",
    "                p_solar, p_grid, battery_charge, solar_power_for_charge = self.compute_p_solar(demand_and_solar_power, date, B)\n",
    "                s = r_peak*(3*p_solar + p_grid)\n",
    "                scores.loc[idx, :] = [r_peak, p_solar, s]\n",
    "                idx += 1\n",
    "                pbar.update()\n",
    "        scores.index = [BatteryPowerDispatcher.format_dispatch_columns(start_date+datetime.timedelta(days=i)) for i in range(7)]\n",
    "        self.scores = scores\n",
    "        self.scores_mean = scores.mean()\n",
    "        return scores, scores.mean()\n",
    "\n",
    "class MultiScoresComparator:\n",
    "    def __init__(self,dp, pred_first_days):\n",
    "        self.dp = dp\n",
    "        self.pred_first_days = pred_first_days\n",
    "    def write_B_on_several_weeks_with_one_method(self,B_dir, data_preprocess= None, predict_first_days=None,\n",
    "                                                pred_demand=False, pred_pv=False,\n",
    "                                                weather_cols_demand=None, weather_cols_pv=None,\n",
    "                                                nb_weeks_before_demand=4, nb_weeks_before_pv= 5,\n",
    "                                                model_demand=RandomForestRegressor(random_state=2019, n_estimators=450),\n",
    "                                                model_pv=RandomForestRegressor(random_state=2019, n_estimators=300)):\n",
    "        if data_preprocess is None:\n",
    "            dp = self.dp\n",
    "        else:\n",
    "            dp=data_preprocess\n",
    "        if predict_first_days is None:\n",
    "            pred_first_days = self.pred_first_days\n",
    "        else:\n",
    "            pred_first_days = predict_first_days\n",
    "        with tqdm(total=len(pred_first_days), file=sys.stdout) as pbar:\n",
    "            for pred_first_day in pred_first_days:\n",
    "                mp=MLPredictor(dp, pred_first_day)\n",
    "                mp.get_demand_previous_week()\n",
    "                if (pred_demand or pred_pv):\n",
    "                    mp.get_weather_prediction(dp.weather_path)\n",
    "                if pred_demand:\n",
    "                    mp.predict_demand_from_past_and_weather(model_demand, nb_week_before=nb_weeks_before_demand, \n",
    "                                                            weather_cols=weather_cols_demand)\n",
    "                if pred_pv:\n",
    "                    mp.predict_solar_power_weeks_before(model_pv, nb_week_before=nb_weeks_before_pv, \n",
    "                                                        weather_cols=weather_cols_pv)\n",
    "                else:\n",
    "                    mp.get_solar_power_previous_week()\n",
    "                bdp = BatteryPowerDispatcher\n",
    "                B_total = bdp.get_all_dispatch_in_a_week(bdp,mp.predicted_df, pred_first_day)\n",
    "                B = bdp.format_dispatching_for_competition(B_total, mp.predicted_df.index)\n",
    "                B.to_csv('{}first_day_{}.csv'.format(B_dir, BatteryPowerDispatcher.format_dispatch_columns(pred_first_day)))\n",
    "                pbar.update()\n",
    "        \n",
    "    def get_scores_on_several_weeks(self,B_dir,predict_first_days=None,data_preprocesser=None):\n",
    "        if data_preprocesser is None:\n",
    "            dp = self.dp\n",
    "        else:\n",
    "            dp=data_preprocesser\n",
    "        if predict_first_days is None:\n",
    "            pred_first_days = self.pred_first_days\n",
    "        else:\n",
    "            pred_first_days = predict_first_days\n",
    "        scores = []\n",
    "        scores_mean = []\n",
    "        with tqdm(total=len(pred_weeks), file=sys.stdout) as pbar:\n",
    "            for pred_first_day in pred_first_days:\n",
    "                sc = ScoreComputer('{}first_day_{}.csv'.format(B_dir, BatteryPowerDispatcher.format_dispatch_columns(pred_first_day)))\n",
    "                score, score_mean = sc.compute_scores(dp.df, pred_first_day)\n",
    "                scores.append(score)\n",
    "                scores_mean.append(score_mean)\n",
    "                pbar.update()\n",
    "        return scores, scores_mean\n",
    "    \n",
    "    def compare_scores(self, scores, predict_first_days=None):\n",
    "        if predict_first_days is None:\n",
    "            pred_first_days = self.pred_first_days\n",
    "        else:\n",
    "            pred_first_days = predict_first_days\n",
    "        score_cols = ['week', 'dow']\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_r_peak'.format(name))\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_p_solar'.format(name))\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_s'.format(name))\n",
    "        score_comps = []\n",
    "        for i in range(len(pred_first_days)):\n",
    "            score_comp = pd.DataFrame(index=scores[list(scores.keys())[0]][0].index)\n",
    "            score_comp['date_in_number'] = score_comp.index\n",
    "            score_comp['first_day_pred'] = pred_first_days[i]\n",
    "            for name in list(scores.keys()):\n",
    "                scores[name][i] = scores[name][i].rename(columns={'r_peak': '{}_r_peak'.format(name), 'p_solar': '{}_p_solar'.format(name), \n",
    "                                                  's': '{}_s'.format(name)})\n",
    "                score_comp = pd.merge(score_comp,scores[name][i] , how='outer', left_index=True, right_index=True)\n",
    "            score_comps.append(score_comp)\n",
    "        score_comps = pd.concat(score_comps)\n",
    "        score_comps = score_comps[score_cols]\n",
    "        score_comps.index = range(score_comps.shape[0])\n",
    "        return score_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-rough",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
