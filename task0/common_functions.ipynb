{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solid-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, BayesianRidge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pvlib import solarposition\n",
    "\n",
    "class DataPreprocesser:\n",
    "    weather_path=None\n",
    "    demand_path=None\n",
    "    solar_path=None\n",
    "    df=None\n",
    "    def __init__(self, weather_path, demand_path, solar_path):\n",
    "        self.weather_path = weather_path\n",
    "        self.demand_path = demand_path\n",
    "        self.solar_path = solar_path\n",
    "    def load_df(self):\n",
    "        weather_df = pd.read_csv(self.weather_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        solar_df = pd.read_csv(self.solar_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        demand_df = pd.read_csv(self.demand_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        df=pd.merge(demand_df,solar_df , how='outer', left_index=True, right_index=True)\n",
    "        df=pd.merge(df,weather_df, how='outer', left_index=True, right_index=True)\n",
    "        df['week']=pd.Int64Index(df.index.isocalendar().week)\n",
    "        df['dow']=df.index.dayofweek\n",
    "        df['hour'] = df.index.hour\n",
    "        df['sp'] = df.hour*2 +df.index.minute/30 + 1\n",
    "        self.df = df\n",
    "    def set_df(self,df):\n",
    "        self.df = df\n",
    "    def remove_nan(self):\n",
    "        self.df = self.df.dropna(subset = ['demand_MW']).interpolate()\n",
    "    def interpolate_df(self):\n",
    "        self.df = self.df.interpolate()\n",
    "    def get_zenith_angle(self):\n",
    "        lat = -4.034\n",
    "        long = 50.33\n",
    "        self.df['zenith_angle'] = solarposition.get_solarposition(self.df.index, lat, long)['apparent_zenith'].values\n",
    "        return self.df\n",
    "    def build_input_for_ml_algo(self, X_column_names, y_column_names):\n",
    "        if self.df is None:\n",
    "            print('df is None, you have to load it')\n",
    "            return self.df\n",
    "        X = self.df[X_column_names].to_numpy()\n",
    "        y = self.df[y_column_names].to_numpy()[:,0]\n",
    "        return X, y\n",
    "    def get_columns_of_group_names(self,group_names, location_numbers, df=None):\n",
    "        columns_names = []\n",
    "        for name in group_names:\n",
    "            for i in location_numbers:\n",
    "                column_name = '{}_location{}'.format(name, i)\n",
    "                if df is None:\n",
    "                    this_df = self.df\n",
    "                else:\n",
    "                    this_df = df\n",
    "                if column_name in this_df.columns.to_list():\n",
    "                    columns_names.append(column_name)\n",
    "                else:\n",
    "                    print('{} is not in df columns'.format(column_name))\n",
    "        return columns_names\n",
    "    \n",
    "    \n",
    "class BatteryPowerDispatcher:\n",
    "    def __init__(self):\n",
    "        return \n",
    "    def get_ideal_discharge_dispatch(df,week,dow, battery_charge=6):#afternoon discharge\n",
    "    \n",
    "        sl  = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']>=32)&(df['sp']<=42),['demand_MW','pv_power_mw','hour']]\n",
    "        peak_ini = sl['demand_MW'].max()\n",
    "\n",
    "        peak_target  = peak_ini-2.5\n",
    "        discharge = (sl['demand_MW']-peak_target).clip(lower = 0)\n",
    "\n",
    "        energy =discharge.sum()*0.5\n",
    "        sp = len(discharge[discharge>0])\n",
    "    \n",
    "        while (energy>battery_charge):\n",
    "\n",
    "            peak_target  =  peak_target +0.01\n",
    "            discharge = (sl['demand_MW']-peak_target).clip(lower=0)\n",
    "            energy =discharge.sum()*0.5\n",
    "        \n",
    "        return(discharge,peak_ini,peak_target)\n",
    "    \n",
    "    def get_ideal_discharge_dispatch_in_a_week(self,df, week, max_battery_charge_in_week=[6,6,6,6,6,6,6]):\n",
    "        res = pd.DataFrame(columns = ['peak_ini','peak_target','energy','solar_energy','duration','week','dow'])\n",
    "        dispatch_summary = pd.DataFrame(index= range(32,43))\n",
    "        idx = 0\n",
    "        for dow in range(0,7):\n",
    "            discharge,peak_ini,peak_target = self.get_ideal_discharge_dispatch(df,week,dow, max_battery_charge_in_week[dow])\n",
    "            energy = discharge.sum()*0.5\n",
    "            sp = len(discharge[discharge>0])\n",
    "            dispatch_summary[str(week*10)+str(dow)]=discharge.values\n",
    "            idx = idx+1\n",
    "            solar_available = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']<=31),'pv_power_mw'].sum()*0.5\n",
    "            res.loc[idx,:] = [peak_ini,peak_target,energy,solar_available,sp,week,dow]\n",
    "        return (dispatch_summary, res)\n",
    "    \n",
    "    def get_charge_of_battery_repartition(df, week, dow, max_charge=6):\n",
    "        solar_power  = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        max_power = 2.5\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_mw'].apply(lambda x: min(x, max_power))\n",
    "        max_charge_from_solar = solar_power['pv_power_norm'].sum()*0.5\n",
    "        charge_from_solar = min(max_charge_from_solar, max_charge)\n",
    "        solar_power['pv_power_norm'] = solar_power['pv_power_norm']*charge_from_solar / max_charge_from_solar\n",
    "        max_charge_from_grid = max_charge-charge_from_solar\n",
    "        battery_B = pd.DataFrame(data=solar_power['pv_power_norm'].to_list(),columns=['solar_B'],index=solar_power.index)\n",
    "        charge_power_from_grid = pd.DataFrame(columns=['grid_B'])\n",
    "        charge_from_grid = 0\n",
    "        for idx in range(31):\n",
    "            power_from_solar = solar_power['pv_power_norm'].values[idx]\n",
    "            charge_power_from_grid.loc[idx,:] = min(max(max_power - power_from_solar,0), max(max_charge_from_grid - charge_from_grid,0)*2)\n",
    "            charge_from_grid = charge_power_from_grid['grid_B'].sum()*0.5\n",
    "        battery_B['sp'] = solar_power['sp'].to_list()\n",
    "        battery_B['grid_B'] = charge_power_from_grid['grid_B'].to_list()\n",
    "        battery_B['B'] = battery_B['solar_B'] + battery_B['grid_B']\n",
    "        return (charge_from_solar, charge_from_grid, battery_B)\n",
    "    \n",
    "    def get_charge_of_battery_repartition2(df, week, dow, max_charge=6):\n",
    "        solar_power = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        solar_power['ind'] = solar_power['sp'].apply(lambda x: int(x))\n",
    "        max_power = 2.5\n",
    "        uncertainty = 0.8\n",
    "        ratio = solar_power['pv_power_mw'].apply(lambda x: min(x,max_power)).sum()*0.5\n",
    "        if ratio > 1.5:\n",
    "            coeff = uncertainty\n",
    "        elif ratio > 1.2:\n",
    "            coeff = 0.9\n",
    "        else:\n",
    "            coeff = 1\n",
    "        solar_power = solar_power.sort_values('pv_power_mw', ascending=False)\n",
    "        max_solar_charge = min(max_charge,solar_power['pv_power_mw'].apply(lambda x: min(x,2,5)).sum()*0.5)\n",
    "        max_grid_charge = max_charge - max_solar_charge\n",
    "        solar_charge = 0\n",
    "        grid_charge = 0\n",
    "        battery_B = pd.DataFrame(columns = ['ind', 'sp', 'solar_B', 'grid_B'])\n",
    "        for i in range (len(solar_power)):\n",
    "            solar_B = min(coeff*min(solar_power['pv_power_mw'][i], max_power), max(0,max_solar_charge - solar_charge)*2)\n",
    "            grid_B = min(max_power-solar_B, max(0,(max_grid_charge-grid_charge)*2))\n",
    "            battery_B.loc[i, :] = [solar_power['ind'][i], solar_power['sp'][i], solar_B, grid_B]\n",
    "            solar_charge += solar_B*0.5\n",
    "            grid_charge += grid_B*0.5\n",
    "        battery_B['B'] = battery_B['solar_B'] + battery_B['grid_B']\n",
    "        battery_B =battery_B.sort_values('ind', ascending = True)\n",
    "        battery_B.index = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']<=31),:].index\n",
    "        battery_B = battery_B.drop('ind', axis=1)\n",
    "        return (solar_charge, grid_charge, battery_B)\n",
    "    \n",
    "    def get_solar_energy_proportion_by_day_in_a_week(self,df,week, charge_method=1,max_battery_charge_in_week=[6,6,6,6,6,6,6]):\n",
    "        B = pd.DataFrame(index= range(1,32))\n",
    "        p_solar = []\n",
    "        for dow in range(7):\n",
    "            if charge_method == 1:\n",
    "                charge_from_solar, charge_from_grid, battery_B = self.get_charge_of_battery_repartition(\n",
    "                    df, week, dow, max_battery_charge_in_week[dow])\n",
    "            elif charge_method == 2:\n",
    "                charge_from_solar, charge_from_grid, battery_B = self.get_charge_of_battery_repartition2(\n",
    "                    df, week, dow, max_battery_charge_in_week[dow])\n",
    "            else:\n",
    "                print(\"ERROR : charge mthod in (1,2)\")\n",
    "                return None, None\n",
    "            B[str(week*10)+str(dow)] = battery_B['B'].to_list()\n",
    "            p_solar.append(charge_from_solar/6)\n",
    "        return p_solar, B\n",
    "    def get_max_solar_energy_available(df, week, dow):\n",
    "        solar_power  = df.loc[(df['week']==week)&(df['dow']==dow)&(df['sp']<=31),['pv_power_mw','sp']]\n",
    "        return min(6,solar_power['pv_power_mw'].apply(lambda x: min(2.5, x)).sum()*0.5)\n",
    "    def get_max_solar_energy_available_in_a_week(self,df, week):\n",
    "        max_solar_energy_available = []\n",
    "        for dow in range(7):\n",
    "            max_solar_energy_available.append(self.get_max_solar_energy_available(df, week, dow))\n",
    "        return max_solar_energy_available\n",
    "    def get_end_of_the_day_dispatch(week):\n",
    "        B_end_of_the_day = pd.DataFrame(index= range(43,49))\n",
    "        for dow in range(0,7):\n",
    "            B_end_of_the_day[str(week*10)+str(dow)]=0\n",
    "        return B_end_of_the_day\n",
    "    def get_all_dispatch_in_a_week(self,df, week, charge_method=1,full_solar=False):\n",
    "        if full_solar:\n",
    "            max_battery_charge_in_week = self.get_max_solar_energy_available_in_a_week(self, df, week)\n",
    "        else:\n",
    "            max_battery_charge_in_week = [6,6,6,6,6,6,6]\n",
    "        p_solar, B_charge = self.get_solar_energy_proportion_by_day_in_a_week(self,df, week, charge_method,max_battery_charge_in_week)\n",
    "        B_discharge, res = self.get_ideal_discharge_dispatch_in_a_week(self, df, week, max_battery_charge_in_week)\n",
    "        B_discharge = -B_discharge\n",
    "        B_end_of_the_day = self.get_end_of_the_day_dispatch(week)\n",
    "        B_total = B_charge.append(B_discharge)\n",
    "        B_total = B_total.append(B_end_of_the_day)\n",
    "        return B_total\n",
    "    def format_dispatching_for_competition(B, index):\n",
    "        final_B = []\n",
    "        for column in B.columns.to_list():\n",
    "            final_B.append(B[column])\n",
    "        final_B = pd.concat(final_B, ignore_index=True)\n",
    "        final_B.index = index\n",
    "        final_B = pd.DataFrame(final_B, columns=['charge_MW'])\n",
    "        return final_B\n",
    "    \n",
    "class MachineLearningResearcher:\n",
    "    param_grids = {}\n",
    "    models = {}\n",
    "    X = None\n",
    "    y = None\n",
    "    scores = {}\n",
    "    best_score = {}\n",
    "    def __init__(self, X, y):\n",
    "        self.param_grids['SVR'] = {'kernel': ['rbf'], 'C': [0.2, 0.4, 0.6, 0.8, 1.0], 'gamma': ['scale', 'auto'], 'epsilon': [0.1,0.05,0.2]}\n",
    "        self.param_grids['KNeighborsRegressor'] = {'n_neighbors': np.arange(3,100).tolist()}\n",
    "        self.param_grids['GradientBoostingRegressor'] = {'loss': ['ls'], 'n_estimators': [50,100, 150, 200], 'learning_rate': [0.025,0.03,0.04,0.05,0.075,0.1,0.15,0.2,0.5]}\n",
    "        self.param_grids['Lasso, Ridge, ElasticNet'] = {'alpha': np.round(np.arange(0.1,1.1, 0.1), decimals=1).tolist()}\n",
    "        self.param_grids['RandomForestRegressor'] = {'n_estimators': np.arange(50, 500, 50).tolist()}\n",
    "        self.models['SVR'] = [SVR()]\n",
    "        self.models['KNeighborsRegressor'] = [KNeighborsRegressor()]\n",
    "        self.models['GradientBoostingRegressor'] = [GradientBoostingRegressor()]\n",
    "        self.models['Lasso, Ridge, ElasticNet'] = [Lasso(), Ridge(), ElasticNet()]\n",
    "        self.models['RandomForestRegressor'] = [RandomForestRegressor()]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def compute_best_scores_and_params_of_ml_algos(self,X, y, models, param_grid):\n",
    "        search_results = {}\n",
    "        search_results['best_model'] = None\n",
    "        search_results['best_scores'] = 0\n",
    "        search_results['best_parameters'] = None\n",
    "        for model in models:\n",
    "            search = GridSearchCV(model, param_grid, cv=5)\n",
    "            search.fit(X, y)\n",
    "            if (search.best_score_ > search_results['best_scores']):\n",
    "                search_results['best_model'] = model\n",
    "                search_results['best_scores'] = search.best_score_\n",
    "                search_results['best_parameters'] = search.best_params_\n",
    "        return search_results\n",
    "    def display_ml_algo_scores(self, scores=None):\n",
    "        fig, ax = plt.subplots(figsize=(14,14))\n",
    "        if scores is None:\n",
    "            algo_scores = self.scores\n",
    "        else:\n",
    "            algo_scores = scores\n",
    "        for model_name in algo_scores:\n",
    "            ax.scatter([model_name], [algo_scores[model_name]['best_scores']], label=model_name)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "        return\n",
    "    def get_best_scores_and_params_of_ml_algos(self, models_names, param_grid=None):\n",
    "        if param_grid is None:\n",
    "            self.scores[models_names] = self.compute_best_scores_and_params_of_ml_algos(self.X, self.y, self.models[models_names], self.param_grids[models_names])\n",
    "        else:\n",
    "            self.scores[models_names] = self.compute_best_scores_and_params_of_ml_algos(self.X, self.y, self.models[models_names], param_grid) \n",
    "        return self.scores[models_names]\n",
    "    def get_best_model_with_best_score(self, scores=None):\n",
    "        def get_best_score(scores):\n",
    "            best_score = {}\n",
    "            best_score['best_scores'] = 0\n",
    "            for score_name in scores:\n",
    "                if float(scores[score_name]['best_scores']) > float(best_score['best_scores']):\n",
    "                    best_score = scores[score_name]\n",
    "            return best_score\n",
    "        if scores is None:\n",
    "            self.best_score = get_best_score(self.scores)\n",
    "        else:\n",
    "            self.best_score = get_best_score(scores)\n",
    "        return self.best_score\n",
    "    \n",
    "class DataVisualiser:\n",
    "    def __init__():\n",
    "        return\n",
    "    def display_correlation_color_map(df, columns_names):\n",
    "        f, ax = plt.subplots(figsize=(20,20))\n",
    "        sns.heatmap(df[columns_names].corr(), annot=True, square=True, cmap = 'coolwarm')\n",
    "        plt.show()\n",
    "    def pair_plot(df, columns_names, hue_name):\n",
    "        if len(columns_names) != 3:\n",
    "            print('columns_names should have exactly 3 names, that\\'s not the case here : ', columns_names)\n",
    "        elif not(isinstance(hue_name, str)):\n",
    "            print('hue_name should be a string, that\\'s not the case here : ', hue_name)\n",
    "        else:\n",
    "            sns.pairplot(data=df[columns_names], hue=hue_name)\n",
    "    \n",
    "class MLPredictor:\n",
    "    def __init__(self, data_preprocess, week_prediction):\n",
    "        self.data_preprocess = data_preprocess\n",
    "        self.week_prediction = week_prediction\n",
    "        self.predicted_df = data_preprocess.df.loc[data_preprocess.df['week'] == (week_prediction-1), ['week', 'dow', 'sp', 'hour', 'zenith_angle']]\n",
    "        self.predicted_df.index = self.predicted_df.index + pd.DateOffset(7)\n",
    "        self.predicted_df['week']=pd.Int64Index(self.predicted_df.index.isocalendar().week)\n",
    "        self.predicted_df['dow']=self.predicted_df.index.dayofweek\n",
    "        self.predicted_df['hour'] = self.predicted_df.index.hour\n",
    "        self.predicted_df['sp'] = self.predicted_df.hour*2 +self.predicted_df.index.minute/30 + 1\n",
    "        lat = -4.034\n",
    "        long = 50.33\n",
    "        self.predicted_df['zenith_angle'] = solarposition.get_solarposition(self.predicted_df.index, lat, long)['apparent_zenith'].values\n",
    "    def get_field_previous_week(self, field_name):\n",
    "        field_prediction = self.data_preprocess.df.loc[self.data_preprocess.df['week'] == (self.week_prediction-1), field_name].values\n",
    "        if self.predicted_df is not None:\n",
    "            self.predicted_df[field_name] = field_prediction \n",
    "            return self.predicted_df\n",
    "        return field_prediction\n",
    "    def get_demand_previous_week(self):\n",
    "        return self.get_field_previous_week('demand_MW')\n",
    "    def get_solar_power_previous_week(self):\n",
    "        return self.get_field_previous_week('pv_power_mw')\n",
    "    def get_weather_prediction(self,weather_path, pred_df=None):\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = demand_pred\n",
    "        weather_prediction = pd.read_csv(weather_path,parse_dates=['datetime'],index_col=['datetime'])\n",
    "        predicted_df = pd.merge(predicted_df,weather_prediction, how='outer', left_index=True, right_index=True)\n",
    "        predicted_df = predicted_df.dropna(subset = ['demand_MW']).interpolate()\n",
    "        self.predicted_df = predicted_df\n",
    "        return self.predicted_df\n",
    "    def predict_demand_from_past_and_weather(self, model, nb_week_before=4, pred_week=None, data=None, pred_df=None, weather_cols=None):\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if weather_cols is None:\n",
    "            weather_columns = self.data_preprocess.get_columns_of_group_names(['temp'], [1,2,5,6])\n",
    "            weather_columns.append('dow')\n",
    "            weather_columns.append('sp')\n",
    "        else:\n",
    "            weather_columns = weather_cols\n",
    "        if pred_week is None:\n",
    "            predict_week = self.week_prediction\n",
    "        else:\n",
    "            predict_week = pred_week\n",
    "        data_train = data_train[(data_train['week'] >= (predict_week-nb_week_before)) & (data_train['week'] <= predict_week)]\n",
    "        X = data_train[weather_columns].to_numpy()\n",
    "        y = data_train['demand_MW'].to_numpy()\n",
    "        model.fit(X,y)\n",
    "        predicted_df['demand_MW'] = model.predict(predicted_df[weather_columns].values)\n",
    "        self.predicted_df = predicted_df\n",
    "        return predicted_df\n",
    "        \n",
    "    def predict_solar_power_from_weather(self, model, data=None, pred_df=None, weather_cols=None):\n",
    "        def solar_power_prediction_function(x, model, x_solar):\n",
    "            if x_solar == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return model.predict(x)[0]\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if weather_cols is None:\n",
    "            weather_columns = self.data_preprocess.get_columns_of_group_names(['solar'], [1,2,3,5,6])\n",
    "            weather_columns += self.data_preprocess.get_columns_of_group_names(['temp'], [1,2])\n",
    "            weather_columns.append('sp')\n",
    "        else:\n",
    "            weather_columns = weather_cols\n",
    "        X = data_train.loc[data_train['solar_location1'] > 0, weather_columns].values\n",
    "        y = data_train.loc[data_train['solar_location1'] > 0, 'pv_power_mw'].values\n",
    "        model.fit(X,y)\n",
    "        \n",
    "        predicted_df['pv_power_mw'] = predicted_df.apply(lambda x: solar_power_prediction_function(\n",
    "            np.array([x[weather_columns].to_numpy()]), model, x['solar_location1']), axis=1)\n",
    "        self.predicted_df = predicted_df\n",
    "        return predicted_df\n",
    "    def predict_solar_power_weeks_before(self, model, nb_week_before=5, pred_week=None, data=None, pred_df=None, weather_cols=None):\n",
    "        if data is None:\n",
    "            data_train = self.data_preprocess.df\n",
    "        else:\n",
    "            data_train = data\n",
    "        if pred_df is None:\n",
    "            predicted_df = self.predicted_df\n",
    "        else:\n",
    "            predicted_df = pred_df\n",
    "        if pred_week is None:\n",
    "            predict_week = self.week_prediction\n",
    "        else:\n",
    "            predict_week = pred_week\n",
    "        data_train = data_train[(data_train['week'] >= (predict_week-nb_week_before)) & (data_train['week'] <= predict_week)]\n",
    "        return self.predict_solar_power_from_weather(model, data=data_train, weather_cols=weather_cols)\n",
    "class ScoreComputer:\n",
    "    def __init__(self, B_path):\n",
    "        B = pd.read_csv(B_path, parse_dates=['datetime'],index_col=['datetime'])\n",
    "        B['week']=pd.Int64Index(B.index.isocalendar().week)\n",
    "        B['dow']=B.index.dayofweek\n",
    "        B['hour'] = B.index.hour\n",
    "        B['sp'] = B.hour*2 + B.index.minute/30 + 1\n",
    "        self.B = B\n",
    "        \n",
    "    def compute_r_peak(self,demand_and_solar_power,week,dow, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        demand_discharge = demand_and_solar_power.loc[(demand_and_solar_power['week']==week) & \n",
    "                                          (demand_and_solar_power['dow']==dow)&(demand_and_solar_power['sp']>=32)&\n",
    "                                          (demand_and_solar_power['sp']<=42),'demand_MW']\n",
    "        B_discharge = B.loc[(B['week']==week) & (B['dow']==dow)&(B['sp']>=32) & (B['sp']<=42),'charge_MW']\n",
    "        old_peak = demand_discharge.max()\n",
    "        if old_peak == 0:\n",
    "            return 0\n",
    "        new_peak = (B_discharge + demand_discharge).max()\n",
    "        return 100*(old_peak-new_peak)/old_peak\n",
    "    def compute_p_solar(self,demand_and_solar_power, week, dow, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        solar_power_for_charge = demand_and_solar_power.loc[(demand_and_solar_power['week']==week) & \n",
    "                                              (demand_and_solar_power['dow']==dow)&(demand_and_solar_power['sp']<=31),['pv_power_mw']]\n",
    "        B_charge = B.loc[(B['week']==week) & (B['dow']==dow)&(B['sp']<=31),['charge_MW']]\n",
    "        solar_power_for_charge = solar_power_for_charge.merge(B_charge, how='outer', left_index=True, right_index=True)\n",
    "        battery_charge = B_charge['charge_MW'].sum()*0.5\n",
    "        solar_power_for_charge['charge_from_solar_MW'] = solar_power_for_charge.apply(lambda x: min(x['pv_power_mw'], x['charge_MW']), axis=1)\n",
    "        battery_charge_from_solar = solar_power_for_charge['charge_from_solar_MW'].sum()*0.5\n",
    "        if battery_charge == 0:\n",
    "            p_solar = 0\n",
    "        else:\n",
    "            p_solar = battery_charge_from_solar / battery_charge\n",
    "        p_grid = 1-p_solar\n",
    "        return p_solar, p_grid, battery_charge, solar_power_for_charge\n",
    "    def compute_scores(self, demand_and_solar_power, week, B_pred=None):\n",
    "        if B_pred is None:\n",
    "            B = self.B\n",
    "        else:\n",
    "            B = B_pred\n",
    "        scores = pd.DataFrame(columns = ['r_peak', 'p_solar', 's'])\n",
    "        idx = 0\n",
    "        with tqdm(total=7, file=sys.stdout) as pbar:\n",
    "            for dow in range(7):\n",
    "                r_peak = self.compute_r_peak(demand_and_solar_power, week, dow, B)\n",
    "                p_solar, p_grid, battery_charge, solar_power_for_charge = self.compute_p_solar(demand_and_solar_power, week, dow, B)\n",
    "                s = r_peak*(3*p_solar + p_grid)\n",
    "                scores.loc[idx, :] = [r_peak, p_solar, s]\n",
    "                idx += 1\n",
    "                pbar.update()\n",
    "        scores.index = ['dow {}'.format(i) for i in range(7)]\n",
    "        self.scores = scores\n",
    "        self.scores_mean = scores.mean()\n",
    "        return scores, scores.mean()\n",
    "\n",
    "class MultiScoresComparator:\n",
    "    def __init__(self,dp, pred_weeks):\n",
    "        self.dp = dp\n",
    "        self.pred_weeks = pred_weeks\n",
    "    def write_B_on_several_weeks_with_one_method(self,B_dir, data_preprocess= None, predict_weeks=None,\n",
    "                                                pred_demand=False, pred_pv=False,\n",
    "                                                weather_cols_demand=None, weather_cols_pv=None,\n",
    "                                                nb_weeks_before_demand=4, nb_weeks_before_pv= 5,\n",
    "                                                model_demand=RandomForestRegressor(random_state=2019, n_estimators=450),\n",
    "                                                model_pv=RandomForestRegressor(random_state=2019, n_estimators=300)):\n",
    "        if data_preprocess is None:\n",
    "            dp = self.dp\n",
    "        else:\n",
    "            dp=data_preprocess\n",
    "        if predict_weeks is None:\n",
    "            pred_weeks = self.pred_weeks\n",
    "        else:\n",
    "            pred_weeks = predict_weeks\n",
    "        with tqdm(total=len(pred_weeks), file=sys.stdout) as pbar:\n",
    "            for pred_week in pred_weeks:\n",
    "                mp=MLPredictor(dp, pred_week)\n",
    "                mp.get_demand_previous_week()\n",
    "                if (pred_demand or pred_pv):\n",
    "                    mp.get_weather_prediction(dp.weather_path)\n",
    "                if pred_demand:\n",
    "                    mp.predict_demand_from_past_and_weather(model_demand, nb_week_before=nb_weeks_before_demand, \n",
    "                                                            weather_cols=weather_cols_demand)\n",
    "                if pred_pv:\n",
    "                    mp.predict_solar_power_weeks_before(model_pv, nb_week_before=nb_weeks_before_pv, \n",
    "                                                        weather_cols=weather_cols_pv)\n",
    "                else:\n",
    "                    mp.get_solar_power_previous_week()\n",
    "                bdp = BatteryPowerDispatcher\n",
    "                B_total = bdp.get_all_dispatch_in_a_week(bdp,mp.predicted_df, pred_week)\n",
    "                B = bdp.format_dispatching_for_competition(B_total, mp.predicted_df.index)\n",
    "                B.to_csv('{}week{}.csv'.format(B_dir, pred_week))\n",
    "                pbar.update()\n",
    "        \n",
    "    def get_scores_on_several_weeks(self,B_dir,predict_weeks=None,data_preprocesser=None):\n",
    "        if data_preprocesser is None:\n",
    "            dp = self.dp\n",
    "        else:\n",
    "            dp=data_preprocesser\n",
    "        if predict_weeks is None:\n",
    "            pred_weeks = self.pred_weeks\n",
    "        else:\n",
    "            pred_weeks = predict_weeks\n",
    "        scores = []\n",
    "        scores_mean = []\n",
    "        with tqdm(total=len(pred_weeks), file=sys.stdout) as pbar:\n",
    "            for pred_week in pred_weeks:\n",
    "                sc = ScoreComputer('{}week{}.csv'.format(B_dir, pred_week))\n",
    "                score, score_mean = sc.compute_scores(dp.df, pred_week)\n",
    "                scores.append(score)\n",
    "                scores_mean.append(score_mean)\n",
    "                pbar.update()\n",
    "        return scores, scores_mean\n",
    "    \n",
    "    def compare_scores(self, scores, predict_weeks=None):\n",
    "        if predict_weeks is None:\n",
    "            pred_weeks = self.pred_weeks\n",
    "        else:\n",
    "            pred_weeks = predict_weeks\n",
    "        score_cols = ['week', 'dow']\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_r_peak'.format(name))\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_p_solar'.format(name))\n",
    "        for name in list(scores.keys()):\n",
    "            score_cols.append('{}_s'.format(name))\n",
    "        score_comps = []\n",
    "        for i in range(len(pred_weeks)):\n",
    "            score_comp = pd.DataFrame(index=scores[list(scores.keys())[0]][0].index)\n",
    "            score_comp['dow'] = score_comp.index\n",
    "            score_comp['dow'] = score_comp['dow'].apply(lambda x: x.replace('dow ',''))\n",
    "            score_comp['week'] = pred_weeks[i]\n",
    "            for name in list(scores.keys()):\n",
    "                scores[name][i] = scores[name][i].rename(columns={'r_peak': '{}_r_peak'.format(name), 'p_solar': '{}_p_solar'.format(name), \n",
    "                                                  's': '{}_s'.format(name)})\n",
    "                score_comp = pd.merge(score_comp,scores[name][i] , how='outer', left_index=True, right_index=True)\n",
    "            score_comps.append(score_comp)\n",
    "        score_comps = pd.concat(score_comps)\n",
    "        score_comps = score_comps[score_cols]\n",
    "        score_comps.index = range(score_comps.shape[0])\n",
    "        return score_comps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
